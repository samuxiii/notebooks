{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "#load the files\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "\n",
    "#size of training dataset\n",
    "train_samples = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             True\n",
       "Cabin           True\n",
       "Embarked        True\n",
       "Fare            True\n",
       "Name           False\n",
       "Parch          False\n",
       "PassengerId    False\n",
       "Pclass         False\n",
       "Sex            False\n",
       "SibSp          False\n",
       "Survived        True\n",
       "Ticket         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((train,test)).isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by='Survived').PassengerId.count()\n",
    "\n",
    "# double number of not survived that survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Name.apply(lambda s: s.split(\". \")[0].split(\", \")[1]  ).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def scale(X, fit_scaler=False):\n",
    "    # Input is a dataframe\n",
    "    #\n",
    "    # Note the way of scaling (df[df.columns])\n",
    "    # we want to mantain the dataframe (instead of numpy array)\n",
    "    if fit_scaler:\n",
    "        X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "    else:\n",
    "        X[X.columns] = scaler.transform(X[X.columns])\n",
    "        \n",
    "    return X \n",
    "\n",
    "def preprocess(df):\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})\n",
    "    X['Family'] = df.Parch + df.Parch\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting a scatter matrix\n",
    "def plot_matrix(X_train, y_train):\n",
    "    colormap = {0:'firebrick',1:'steelblue'}\n",
    "    colors = np.vectorize(colormap.get)(y_train)\n",
    "\n",
    "    pd.plotting.scatter_matrix(X_train, c=colors, marker = 'o', s=30,\n",
    "                               hist_kwds={'bins':15}, figsize=(9,9));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file(clf, X_test):\n",
    "    import os\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    passengerId = 892\n",
    "    file = \"PassengerId,Survived\" + os.linesep\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        file += \"{},{}\".format(passengerId, (int)(predictions[i]))  + os.linesep\n",
    "        passengerId += 1\n",
    "\n",
    "    # Save to file\n",
    "    with open('attempt.txt', 'w') as f:\n",
    "        f.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def baseline(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    dummy = DummyClassifier(random_state=0)\n",
    "\n",
    "    #be aware of y as column vector\n",
    "    dummy.fit(X_train, y_train.values.reshape(-1))\n",
    "    acc = dummy.score(X_val.values, y_val.values.reshape(-1))\n",
    "    print('Accuracy: {:.2f}\\n'.format(acc))\n",
    "    \n",
    "    # Combined report with all above metrics\n",
    "    print(classification_report(y_val, dummy.predict(X_val), target_names=['Not Survived', 'Survived']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline starts from 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.63      0.62      0.63       139\n",
      "    Survived       0.39      0.40      0.40        84\n",
      "\n",
      " avg / total       0.54      0.54      0.54       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess(train)\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "baseline(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "\n",
    "def check_model(X, y):\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    scores = cross_validate(rfc, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "    print(\"Train scores: {:.3f}\".format(scores['train_score'].mean()))\n",
    "    print(\"Test scores: {:.3f}\".format(scores['test_score'].mean()))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rfc.predict(X_val)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "    y_probs = rfc.predict_proba(X_val)\n",
    "    auc = roc_auc_score(y_val, y_probs[:,1])\n",
    "    print(\"AUC:{:.3f}\".format(auc))\n",
    "    \n",
    "    print(classification_report(y_val, y_pred, target_names=['Not Survived', 'Survived']))\n",
    "    \n",
    "    return rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "\n",
    "def grid_search(X, y, test_size=0.25):\n",
    "    max_range = np.append(np.arange(1, X.shape[1]+1), None)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    params = {'n_estimators': [2, 3, 5, 7, 10, 20],\n",
    "              'class_weight': ['balanced', {1:2}, {1:3}, {1:4}, {1:5}, {1:10}, {1:20}],\n",
    "              'max_features': max_range,\n",
    "              'max_depth': max_range}\n",
    "    \n",
    "    params = {'n_estimators': [25, 50],\n",
    "              'class_weight': ['balanced', {1:2}],\n",
    "              'bootstrap': [True, False]}\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    grid_rfc = GridSearchCV(rfc, param_grid=params, cv=10, scoring='accuracy')\n",
    "    grid_rfc.fit(X_train, y_train)\n",
    "\n",
    "    best_rfc = grid_rfc.best_estimator_\n",
    "\n",
    "    y_pred = best_rfc.predict(X_val)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "    y_probs = best_rfc.predict_proba(X_val)\n",
    "    auc = roc_auc_score(y_val, y_probs[:,1])\n",
    "    print(\"AUC:{:.3f}\".format(auc))\n",
    "    \n",
    "    print(\"Best params: {}\\n\".format(grid_rfc.best_params_))\n",
    "    print(classification_report(y_val, y_pred, target_names=['Not Survived', 'Survived']))\n",
    "    \n",
    "    return best_rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.807\n",
      "Test scores: 0.795\n",
      "Accuracy: 0.794\n",
      "AUC:0.867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.85      0.84       139\n",
      "    Survived       0.74      0.70      0.72        84\n",
      "\n",
      " avg / total       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess(train).values\n",
    "y_train = train[['Survived']].values.reshape(-1)\n",
    "\n",
    "rfc = check_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = preprocess(test)\n",
    "save_to_file(rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.77511 in Kaggle!!!\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.807\n",
      "Test scores: 0.795\n",
      "Accuracy: 0.794\n",
      "AUC:0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.85      0.84       139\n",
      "    Survived       0.74      0.70      0.72        84\n",
      "\n",
      " avg / total       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = scale(preprocess(train), True)\n",
    "rfc = check_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = preprocess(test)\n",
    "X_test = scale(X_test)\n",
    "save_to_file(rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle 0.77511 -> Same results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_2(df):\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})  \n",
    "    X['Family'] = (df.SibSp*df.Parch)/(df.SibSp + df.Parch + 0.0001)\n",
    "    \n",
    "    X['Age'] = df.Age.fillna(df.Age.median())\n",
    "    group_pclass_fare = df.groupby(by='Pclass').Fare.median()\n",
    "    X['Fare'] = np.where(df.Fare.isnull(), group_pclass_fare[df.Pclass], df.Fare)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.965\n",
      "Test scores: 0.816\n",
      "Accuracy: 0.852\n",
      "AUC:0.862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.86      0.91      0.89       139\n",
      "    Survived       0.84      0.75      0.79        84\n",
      "\n",
      " avg / total       0.85      0.85      0.85       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess_2(train)\n",
    "rfc = check_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = preprocess_2(test)\n",
    "save_to_file(rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle 0.74641\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex(data):\n",
    "    data.Sex = data.Sex.map({'female':1, 'male':0})\n",
    "    return data\n",
    "\n",
    "def process_embarked(data):\n",
    "    #fill with most common\n",
    "    most_common = data['Embarked'].value_counts().index[0]\n",
    "    data.Embarked = data.Embarked.fillna(most_common)\n",
    "    #U of unknown\n",
    "    #data.Embarked = data.Embarked.fillna('U')\n",
    "    #data.Embarked = data.Embarked.map({'S':0,'C':1,'Q':2,'U':3})\n",
    "    dummies = pd.get_dummies(data.Embarked, prefix='Embarked')\n",
    "    data = pd.concat([data, dummies], axis=1).drop('Embarked', axis=1)\n",
    "    return data\n",
    "\n",
    "def process_family(data):\n",
    "    data['Family'] = data.SibSp + data.Parch\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_name(data):\n",
    "    dict_names = {\n",
    "                \"Capt\":       \"Officer\",\n",
    "                \"Col\":        \"Officer\",\n",
    "                \"Major\":      \"Officer\",\n",
    "                \"Jonkheer\":   \"Royalty\",\n",
    "                \"Don\":        \"Royalty\",\n",
    "                \"Sir\" :       \"Royalty\",\n",
    "                \"Dr\":         \"Officer\",\n",
    "                \"Rev\":        \"Officer\",\n",
    "                \"the Countess\":\"Royalty\",\n",
    "                \"Dona\":       \"Royalty\",\n",
    "                \"Mme\":        \"Mrs\",\n",
    "                \"Mlle\":       \"Miss\",\n",
    "                \"Ms\":         \"Mrs\",\n",
    "                \"Mr\" :        \"Mr\",\n",
    "                \"Mrs\" :       \"Mrs\",\n",
    "                \"Miss\" :      \"Miss\",\n",
    "                \"Master\" :    \"Master\",\n",
    "                \"Lady\" :      \"Royalty\"\n",
    "                }\n",
    "    \n",
    "    data['Name'] = data.Name.apply(lambda s: s.split(\". \")[0].split(\", \")[1])\n",
    "    data.Name = data.Name.map(dict_names)\n",
    "    dummies = pd.get_dummies(data.Name, prefix='Name')\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "    return data\n",
    "\n",
    "def process_age(data):\n",
    "    grouped_name = data.groupby(by=['Sex','Pclass','Name']).Age.median()\n",
    "\n",
    "    data.Age = data.apply(lambda r: grouped_name[r.Sex, r.Pclass, r.Name] if np.isnan(r.Age) else r.Age, axis=1)\n",
    "    \n",
    "    #Just in case there is no median() por Sex-Pclass-Name\n",
    "    if(data.Age.isnull().any()):\n",
    "        grouped_name_2 = data.groupby(by=['Sex','Pclass']).Age.median()\n",
    "        data.Age = data.apply(lambda r: grouped_name_2[r.Sex, r.Pclass] if np.isnan(r.Age) else r.Age, axis=1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def process_fare(data):\n",
    "    group_pclass_fare = data.groupby(by='Pclass').Fare.median()\n",
    "    data.Fare = np.where(data.Fare.isnull(), group_pclass_fare[data.Pclass], data.Fare)\n",
    "    return data\n",
    "    \n",
    "def process_cabin(data):\n",
    "    data['Deck'] = data.Cabin.str[0]\n",
    "    data.loc[data.Deck.isnull(), 'Deck'] = 'U' #unknown\n",
    "    #data.Deck = data.Deck.map({'NaN':0, 'F':1, 'E':2, 'C':3, 'D':4, 'B':5, 'G':6, 'A':7, 'T':8})\n",
    "    dummies = pd.get_dummies(data.Deck, prefix='Deck')\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "    \n",
    "    data['Room'] = np.where(data.Cabin.isnull(), 999, data.Cabin.str.split().str.get(0).str[1:])\n",
    "    data.Room = pd.to_numeric(data.Room)\n",
    "    data.loc[data.Room.isnull(), 'Room'] = 999\n",
    "    \n",
    "    data = data.drop(['Cabin','Deck'], axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_ticket(data):\n",
    "    #data['TicketNumber'] = data.Ticket.str.extractall(\"(.*\\s)?(.+)\")[1]\n",
    "    data['TicketNumber'] = data.Ticket.str.extract(\"(.*\\s)?(.+)\", expand=True)[1]\n",
    "    #special case LINE\n",
    "    data[data.TicketNumber=='LINE'] = 0\n",
    "    data.TicketNumber = data.TicketNumber.astype('int64')\n",
    "    #data[\"TicketGroupSize\"] = data.groupby('TicketNumber')['TicketNumber'].transform('count') - 1 \n",
    "    \n",
    "    data = data.drop('Ticket', axis=1)\n",
    "    return data\n",
    "\n",
    "def process(data):\n",
    "    data = process_sex(data)\n",
    "    data = process_embarked(data)\n",
    "    data = process_family(data)\n",
    "    data = process_name(data)\n",
    "    data = process_age(data)\n",
    "    data = process_fare(data)\n",
    "    data = process_cabin(data)\n",
    "    data = process_ticket(data)\n",
    "    \n",
    "    #data = data.drop('Ticket', axis=1)\n",
    "    data = data.drop('Name', axis=1)\n",
    "    data = data.drop('PassengerId', axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dd = train.Ticket.str.extract(\"(.*\\s)?(.+)\", expand=True)\n",
    "#dd.groupby([0,1])[1].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat for auto generated dummie features from categorical\n",
    "data = pd.concat([train,test])\n",
    "data = process(data)\n",
    "\n",
    "processed_train = data[:train_samples]\n",
    "processed_test = data[train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.984\n",
      "Test scores: 0.826\n",
      "Accuracy: 0.857\n",
      "AUC:0.891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.84      0.96      0.89       139\n",
      "    Survived       0.91      0.69      0.78        84\n",
      "\n",
      " avg / total       0.86      0.86      0.85       223\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = processed_train.drop('Survived', axis=1).values\n",
    "y_train = processed_train[['Survived']].values.ravel()\n",
    "\n",
    "check_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.852\n",
      "AUC:0.903\n",
      "Best params: {'bootstrap': True, 'class_weight': {1: 2}, 'n_estimators': 25}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.85      0.92      0.89       139\n",
      "    Survived       0.85      0.74      0.79        84\n",
      "\n",
      " avg / total       0.85      0.85      0.85       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = grid_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[538,  12],\n",
       "       [ 26, 315]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = processed_test.drop('Survived', axis=1)\n",
    "save_to_file(clf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9330143540669856\n"
     ]
    }
   ],
   "source": [
    "def CHECK():\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    other = pd.read_csv('attempt_79904.txt')\n",
    "    mine = pd.read_csv('attempt.txt')\n",
    "\n",
    "    data = pd.merge(other,mine, on='PassengerId')\n",
    "    acc= accuracy_score(data.Survived_x, data.Survived_y)\n",
    "    \n",
    "    print(\"Acc: {}\".format(acc))\n",
    "\n",
    "CHECK()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
