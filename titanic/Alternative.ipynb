{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "#load the files\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "\n",
    "#size of training dataset\n",
    "train_samples = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by='Survived').PassengerId.count()\n",
    "\n",
    "# double number of not survived that survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Name.apply(lambda s: s.split(\". \")[0].split(\", \")[1]  ).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def scale(X, fit_scaler=False):\n",
    "    # Input is a dataframe\n",
    "    #\n",
    "    # Note the way of scaling (df[df.columns])\n",
    "    # we want to mantain the dataframe (instead of numpy array)\n",
    "    if fit_scaler:\n",
    "        X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "    else:\n",
    "        X[X.columns] = scaler.transform(X[X.columns])\n",
    "        \n",
    "    return X \n",
    "\n",
    "def preprocess(df):\n",
    "    #X = df[['Pclass','Age','SibSp','Parch','Fare','Sex', 'Embarked']]\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})\n",
    "    #X.Embarked.fillna('U', inplace=True)\n",
    "    #X.Embarked = X.Embarked.map({'S':0,'C':1,'Q':2,'U':3})\n",
    "    \n",
    "    X['Family'] = df.Parch + df.Parch\n",
    "    #mask = (df.Parch>0) & (df.SibSp>0)\n",
    "    #X.loc[mask, 'Family'] = 1\n",
    "    \n",
    "    #X['Name'] = train.Name.apply(lambda s: s.split(\". \")[0].split(\", \")[1])\n",
    "    #list_names = train.Name.apply(lambda s: s.split(\". \")[0].split(\", \")[1]).unique()\n",
    "    #dict_names = {v:k for k,v in enumerate(list_names)}\n",
    "    #X.Name = X.Name.map(dict_names)\n",
    "    \n",
    "    #fill NaN Age with the mean of the same name ('Mr', 'Miss',...)\n",
    "    #grp_name_age = X.groupby(by='Name').Age.mean()\n",
    "    #X['Age'] = np.where(X.Age.isnull(), grp_name_age[X.Name], X.Age)\n",
    "    \n",
    "    #X = X.drop('Name',axis=1)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting a scatter matrix\n",
    "def plot_matrix(X_train, y_train):\n",
    "    colormap = {0:'firebrick',1:'steelblue'}\n",
    "    colors = y_train.Survived.map(colormap)\n",
    "\n",
    "    pd.plotting.scatter_matrix(X_train, c=colors, marker = 'o', s=30,\n",
    "                               hist_kwds={'bins':15}, figsize=(9,9));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def baseline(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    dummy = DummyClassifier(random_state=0)\n",
    "\n",
    "    #be aware of y as column vector\n",
    "    dummy.fit(X_train, y_train.values.reshape(-1))\n",
    "    acc = dummy.score(X_val.values, y_val.values.reshape(-1))\n",
    "    print('Accuracy: {:.2f}\\n'.format(acc))\n",
    "    \n",
    "    # Combined report with all above metrics\n",
    "    print(classification_report(y_val, dummy.predict(X_val), target_names=['Not Survived', 'Survived']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.63      0.62      0.63       139\n",
      "    Survived       0.39      0.40      0.40        84\n",
      "\n",
      " avg / total       0.54      0.54      0.54       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess(train)\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "baseline(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline starts from 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.807\n",
      "Test scores: 0.795\n",
      "Accuracy: 0.794\n",
      "AUC:0.867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.85      0.84       139\n",
      "    Survived       0.74      0.70      0.72        84\n",
      "\n",
      " avg / total       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "\n",
    "X_train_1 = X_train.values\n",
    "y_train_1 = y_train.values.reshape(-1)\n",
    "\n",
    "def check_model(X, y):\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    scores = cross_validate(rfc, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "    print(\"Train scores: {:.3f}\".format(scores['train_score'].mean()))\n",
    "    print(\"Test scores: {:.3f}\".format(scores['test_score'].mean()))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rfc.predict(X_val)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "    y_probs = rfc.predict_proba(X_val)\n",
    "    auc = roc_auc_score(y_val, y_probs[:,1])\n",
    "    print(\"AUC:{:.3f}\".format(auc))\n",
    "    \n",
    "    print(classification_report(y_val, y_pred, target_names=['Not Survived', 'Survived']))\n",
    "    \n",
    "check_model(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "\n",
    "def grid_search(X, y, test_size=0.25):\n",
    "    max_range = np.append(np.arange(1, X_train_1.shape[1]+1), None)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    params = {'n_estimators': [2, 3, 5, 7, 10, 20],\n",
    "              'class_weight': ['balanced', {1:2}, {1:3}, {1:4}, {1:5}, {1:10}, {1:20}],\n",
    "              'max_features': max_range,\n",
    "              'max_depth': max_range}\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    grid_rfc = GridSearchCV(rfc, param_grid=params, cv=10, scoring='accuracy')\n",
    "    grid_rfc.fit(X_train, y_train)\n",
    "\n",
    "    best_rfc = grid_rfc.best_estimator_\n",
    "\n",
    "    y_pred = best_rfc.predict(X_val)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "    y_probs = best_rfc.predict_proba(X_val)\n",
    "    auc = roc_auc_score(y_val, y_probs[:,1])\n",
    "    print(\"AUC:{:.3f}\".format(auc))\n",
    "    \n",
    "    print(\"Best params:\\n {}\".format(grid_rfc.best_params_))\n",
    "    print(classification_report(y_val, y_pred, target_names=['Not Survived', 'Survived']))\n",
    "    \n",
    "    return best_rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file(clf, X_test):\n",
    "    import os\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    passengerId = 892\n",
    "    file = \"PassengerId,Survived\" + os.linesep\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        file += \"{},{}\".format(passengerId, (int)(predictions[i]))  + os.linesep\n",
    "        passengerId += 1\n",
    "\n",
    "    # Save to file\n",
    "    with open('attempt.txt', 'w') as f:\n",
    "        f.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794\n",
      "AUC:0.865\n",
      "Best params:\n",
      " {'class_weight': 'balanced', 'max_features': 1, 'n_estimators': 30, 'max_depth': None}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.85      0.84       139\n",
      "    Survived       0.74      0.70      0.72        84\n",
      "\n",
      " avg / total       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess(train)\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "X_train_1 = X_train.values\n",
    "y_train_1 = y_train.values.reshape(-1)\n",
    "\n",
    "best_rfc = grid_search(X_train_1, y_train_1)\n",
    "X_test = preprocess(test)\n",
    "save_to_file(best_rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.77511 in Kaggle!!!\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794\n",
      "AUC:0.867\n",
      "Best params:\n",
      " {'class_weight': 'balanced', 'max_features': 2, 'n_estimators': 5, 'max_depth': None}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.85      0.84       139\n",
      "    Survived       0.74      0.70      0.72        84\n",
      "\n",
      " avg / total       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_2 = scale(X_train, True)\n",
    "best_rfc = grid_search(X_train_2, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = preprocess(test)\n",
    "X_test = scale(X_test)\n",
    "save_to_file(best_rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle 0.70334 -> Scaling gives WORST results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess2(df):\n",
    "    #X = df[['Pclass','Age','SibSp','Parch','Fare','Sex', 'Embarked']]\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})  \n",
    "    X['Family'] = df.SibSp/(df.Parch + 0.00001)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.780\n",
      "AUC:0.836\n",
      "Best params:\n",
      " {'class_weight': 'balanced', 'max_features': 3, 'n_estimators': 2, 'max_depth': 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.80      0.86      0.83       139\n",
      "    Survived       0.73      0.65      0.69        84\n",
      "\n",
      " avg / total       0.78      0.78      0.78       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_3 = preprocess2(train)\n",
    "best_rfc = grid_search(X_train_3, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = preprocess2(test)\n",
    "save_to_file(best_rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle 0.74162\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess2_1(df):\n",
    "    #X = df[['Pclass','Age','SibSp','Parch','Fare','Sex', 'Embarked']]\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})\n",
    "    \n",
    "    X['Family'] = (df.SibSp*df.Parch)/(df.SibSp + df.Parch + 0.0001)\n",
    "    \n",
    "    X['Age'] = df.Age.fillna(df.Age.median())\n",
    "    group_pclass_fare = df.groupby(by='Pclass').Fare.median()\n",
    "    X['Fare'] = np.where(df.Fare.isnull(), group_pclass_fare[df.Pclass], df.Fare)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.822\n",
      "AUC:0.856\n",
      "Best params:\n",
      " {'max_depth': None, 'max_features': 2, 'class_weight': {1: 2}, 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.80      0.92      0.85        51\n",
      "    Survived       0.87      0.69      0.77        39\n",
      "\n",
      " avg / total       0.83      0.82      0.82        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess2_1(train)\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "X_train_1 = X_train.values\n",
    "y_train_1 = y_train.values.reshape(-1)\n",
    "\n",
    "best_rfc2 = grid_search(X_train_1, y_train_1, test_size=0.1)  #0.77511\n",
    "X_test = preprocess2_1(test)\n",
    "save_to_file(best_rfc2, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "AUC:0.889\n",
      "Best params:\n",
      " {'max_depth': 5, 'max_features': 4, 'class_weight': 'balanced', 'n_estimators': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.85      0.88      0.86       139\n",
      "    Survived       0.78      0.74      0.76        84\n",
      "\n",
      " avg / total       0.82      0.83      0.82       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess2_1(train)\n",
    "y_train = train[['Survived']]\n",
    "\n",
    "X_train_1 = X_train.values\n",
    "y_train_1 = y_train.values.reshape(-1)\n",
    "\n",
    "best_rfc2 = grid_search(X_train_1, y_train_1, test_size=0.25)  #0.71770\n",
    "X_test = preprocess2_1(test)\n",
    "save_to_file(best_rfc2, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess3(df):\n",
    "    #X = df[['Pclass','Age','SibSp','Parch','Fare','Sex', 'Embarked']]\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})\n",
    "    X['Embarked'] = df.Embarked.fillna('U')\n",
    "    X.Embarked = X.Embarked.map({'S':0,'C':1,'Q':2,'U':3})\n",
    "    \n",
    "    X['Family'] = (df.SibSp*df.Parch)/(df.SibSp + df.Parch + 0.0001)\n",
    "    \n",
    "    X['Age'] = df.Age.fillna(df.Age.median())\n",
    "    group_pclass_fare = df.groupby(by='Pclass').Fare.median()\n",
    "    X['Fare'] = np.where(df.Fare.isnull(), group_pclass_fare[df.Pclass], df.Fare)\n",
    "    \n",
    "    #X['Deck'] = df.Cabin.str[0]\n",
    "    #X.loc[X.Deck.isnull(), 'Deck'] = 'NaN'\n",
    "    #X['Room'] = \n",
    "    #print(df[~df.Cabin.isnull()].Cabin.str.split())\n",
    "    #X.Deck = X.Deck.map({'NaN':0, 'F':1, 'E':2, 'C':3, 'D':4, 'B':5, 'G':6, 'A':7, 'T':8})\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[~train.Cabin.isnull()].Cabin.str.split().str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess4(df):\n",
    "    #X = df[['Pclass','Age','SibSp','Parch','Fare','Sex', 'Embarked']]\n",
    "    X = df[['Pclass','Sex']].copy()\n",
    "\n",
    "    # feature engineering\n",
    "    X.Sex = X.Sex.map({'female':1, 'male':0})\n",
    "    X['Embarked'] = df.Embarked.fillna('U')\n",
    "    X.Embarked = X.Embarked.map({'S':0,'C':1,'Q':2,'U':3})\n",
    "    \n",
    "    X['Family'] = (df.SibSp*df.Parch)/(df.SibSp + df.Parch + 0.0001)\n",
    "    \n",
    "    X['Age'] = df.Age.fillna(df.Age.median())\n",
    "    group_pclass_fare = df.groupby(by='Pclass').Fare.median()\n",
    "    X['Fare'] = np.where(df.Fare.isnull(), group_pclass_fare[df.Pclass], df.Fare)\n",
    "    \n",
    "    X['Deck'] = df.Cabin.str[0]\n",
    "    X.loc[X.Deck.isnull(), 'Deck'] = 'NaN'\n",
    "    #print(df[~df.Cabin.isnull()].Cabin.str.split())\n",
    "    X.Deck = X.Deck.map({'NaN':0, 'F':1, 'E':2, 'C':3, 'D':4, 'B':5, 'G':6, 'A':7, 'T':8})\n",
    "    \n",
    "    X['Room'] = train[~train.Cabin.isnull()].Cabin.str.split().str.get(0)\n",
    "    X.Room = X.Room.str[1:].fillna(0)\n",
    "    X.Room = X.Room.str[1:]\n",
    "    X.loc[X.Room.isnull(), 'Room'] = 0\n",
    "    X.Room = pd.to_numeric(X.Room)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800\n",
      "AUC:0.900\n",
      "Best params:\n",
      " {'class_weight': {1: 3}, 'max_features': None, 'n_estimators': 50, 'max_depth': None}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.77      0.92      0.84        51\n",
      "    Survived       0.86      0.64      0.74        39\n",
      "\n",
      " avg / total       0.81      0.80      0.79        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train3 = preprocess3(train)\n",
    "y_train3 = train[['Survived']]\n",
    "\n",
    "X_train_13 = X_train3.values\n",
    "y_train_13 = y_train3.values.reshape(-1)\n",
    "\n",
    "best_rfc3 = grid_search(X_train_13, y_train_13, test_size=0.1)\n",
    "X_test3 = preprocess3(test)\n",
    "save_to_file(best_rfc3, X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.807\n",
      "Test scores: 0.795\n",
      "Accuracy: 0.794\n",
      "AUC:0.867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.85      0.84       139\n",
      "    Survived       0.74      0.70      0.72        84\n",
      "\n",
      " avg / total       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = preprocess(train).values\n",
    "y = train[['Survived']].values.reshape(-1)\n",
    "\n",
    "check_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.813\n",
      "Test scores: 0.777\n",
      "Accuracy: 0.767\n",
      "AUC:0.853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.82      0.80      0.81       139\n",
      "    Survived       0.68      0.71      0.70        84\n",
      "\n",
      " avg / total       0.77      0.77      0.77       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = preprocess2(train).values\n",
    "y = train[['Survived']].values.reshape(-1)\n",
    "\n",
    "check_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.965\n",
      "Test scores: 0.816\n",
      "Accuracy: 0.852\n",
      "AUC:0.862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.86      0.91      0.89       139\n",
      "    Survived       0.84      0.75      0.79        84\n",
      "\n",
      " avg / total       0.85      0.85      0.85       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = preprocess2_1(train).values\n",
    "y = train[['Survived']].values.reshape(-1)\n",
    "\n",
    "check_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: 0.966\n",
      "Test scores: 0.797\n",
      "Accuracy: 0.843\n",
      "AUC:0.899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.87      0.88      0.88       139\n",
      "    Survived       0.80      0.77      0.79        84\n",
      "\n",
      " avg / total       0.84      0.84      0.84       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = preprocess3(train).values\n",
    "y = train[['Survived']].values.reshape(-1)\n",
    "\n",
    "check_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5f93e7a91061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess4' is not defined"
     ]
    }
   ],
   "source": [
    "X = preprocess4(train).values\n",
    "y = train[['Survived']].values.reshape(-1)\n",
    "\n",
    "check_model(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
